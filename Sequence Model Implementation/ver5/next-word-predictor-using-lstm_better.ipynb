{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #8b0000; padding: 10px; text-align: center;\">\n",
    "  <h1 style=\"color: #ffffff; text-shadow: 0 0 10px #ff6666;\">Next Word Prdictor Using LSTM</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 20px; border-radius: 10px;\">\n",
    "  <h3 style=\"color: #333333; text-align: center; font-weight: bold;\">What Is Next Word Prediction?</h3>\n",
    "  <p style=\"color: #666666; text-align: justify;\">Next word prediction is a natural language processing (NLP) task that aims to predict the most likely word or sequence of words that will follow a given input text. Iat's a fundamental problem in NLP and has various applications, including text generation, autocomplete suggestions, and machine translation.</p>\n",
    "  <div style=\"background-color: #4CAF50; color: #ffffff; padding: 10px; border-radius: 5px; text-align: center;\">\n",
    "    <p style=\"margin: 0; text-align: center;\">In This Notebook I Will Use Deep LSTM Model For Solve This Problem</p>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #8b0000; padding: 10px; text-align: center;\">\n",
    "  <h1 style=\"color: #ffffff; text-shadow: 0 0 10px #ff6666;\">Import Important Modules</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 00:05:05.571202: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-09 00:05:05.619121: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-09 00:05:05.633722: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-09 00:05:05.739924: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-09 00:05:06.695293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional,Input,Attention,LayerNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #8b0000; padding: 10px; text-align: center;\">\n",
    "  <h1 style=\"color: #ffffff; text-shadow: 0 0 10px #ff6666;\">Data Preparation</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medium_df = pd.read_csv('medium_data.csv')\n",
    "news_df = pd.read_csv('ArticlesMarch2018.csv')\n",
    "large_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728419708.862245    5059 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728419708.977211    5059 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1728419708.977280    5059 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "large_df = large_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "large_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "large_df = large_df.head(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>image</th>\n",
       "      <th>claps</th>\n",
       "      <th>responses</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>publication</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/a-beginners-gui...</td>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.png</td>\n",
       "      <td>850</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                url  \\\n",
       "0   1  https://towardsdatascience.com/a-beginners-gui...   \n",
       "\n",
       "                                               title subtitle  image  claps  \\\n",
       "0  A Beginner’s Guide to Word Embedding with Gens...      NaN  1.png    850   \n",
       "\n",
       "  responses  reading_time           publication        date  \n",
       "0         8             8  Towards Data Science  2019-05-30  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hands-on Graph Neural Networks with PyTorch & PyTorch Geometric'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_df['title'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "      <th>articleWordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a974697410cf7000162e8a4</td>\n",
       "      <td>By BINYAMIN APPELBAUM</td>\n",
       "      <td>article</td>\n",
       "      <td>Virtual Coins, Real Resources</td>\n",
       "      <td>['Bitcoin (Currency)', 'Electric Light and Pow...</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>01-03-2018 00:17</td>\n",
       "      <td>Economy</td>\n",
       "      <td>America has a productivity problem. One explan...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/02/28/business/ec...</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID                 byline documentType  \\\n",
       "0  5a974697410cf7000162e8a4  By BINYAMIN APPELBAUM      article   \n",
       "\n",
       "                        headline  \\\n",
       "0  Virtual Coins, Real Resources   \n",
       "\n",
       "                                            keywords  multimedia   newDesk  \\\n",
       "0  ['Bitcoin (Currency)', 'Electric Light and Pow...           1  Business   \n",
       "\n",
       "   printPage           pubDate sectionName  \\\n",
       "0          1  01-03-2018 00:17     Economy   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  America has a productivity problem. One explan...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \\\n",
       "0           News  https://www.nytimes.com/2018/02/28/business/ec...   \n",
       "\n",
       "   articleWordCount  \n",
       "0              1207  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. Advances Military Plans for North Korea'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['headline'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6508, 10)\n",
      "(1385, 15)\n"
     ]
    }
   ],
   "source": [
    "print(medium_df.shape)\n",
    "print(news_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating New DataFrame\n",
    "text = pd.concat([medium_df['title'], news_df['headline'],large_df['Title']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'text' : text\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which 2020 Candidate is the Best at\\xa0Twitter?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22893, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22007, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #8b0000; padding: 10px; text-align: center;\">\n",
    "  <h1 style=\"color: #ffffff; text-shadow: 0 0 10px #ff6666;\">Data Cleaning</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.replace(u'\\xa0',u' '))\n",
    "data['text'] = data['text'].apply(lambda x: x.replace('\\u200a', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def clean_text(text):\n",
    "    # Unescape HTML escape characters\n",
    "    cleaned_text = html.unescape(text)\n",
    "    # Remove HTML tags\n",
    "    cleaned_text = re.sub(r'<[^>]+>', '', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "data['text'] = data['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oil steady in edgy Asia trading\n"
     ]
    }
   ],
   "source": [
    "print(data['text'][15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22007"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Databricks: How to Save Files in CSV on Your L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>How To Give Yourself Peace In A Rough World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Automation, Full Unemployment and a Future We ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>How To Live A Happier Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>OkyWatch Business Case: F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>Top influential women in blockchain and crypto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     A Beginner’s Guide to Word Embedding with Gens...\n",
       "1     Hands-on Graph Neural Networks with PyTorch & ...\n",
       "2                          How to Use ggplot2 in Python\n",
       "3     Databricks: How to Save Files in CSV on Your L...\n",
       "4     A Step-by-Step Implementation of Gradient Desc...\n",
       "...                                                 ...\n",
       "4998        How To Give Yourself Peace In A Rough World\n",
       "4999  Automation, Full Unemployment and a Future We ...\n",
       "5000                         How To Live A Happier Life\n",
       "5001                          OkyWatch Business Case: F\n",
       "5002  Top influential women in blockchain and crypto...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #8b0000; padding: 10px; text-align: center;\">\n",
    "  <h1 style=\"color: #ffffff; text-shadow: 0 0 10px #ff6666;\">Tokenization</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  <div style=\"background-color: #4CAF50; color: #ffffff; padding: 10px; border-radius: 5px; text-align: center;\">\n",
    "    <p style=\"margin: 0; text-align: center;\">Tokenizatin is the process which we provide an unique id to all the words and make word index or we can say vocabulary</p>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  7091\n",
      "Word: ID\n",
      "--------------\n",
      "<oov>:  1\n",
      "Storng:  1148\n",
      "And:  7\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'consumption'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStorng: \u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m.\u001b[39mword_index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrong\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnd: \u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m.\u001b[39mword_index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConsumption: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconsumption\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'consumption'"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "print('Total number of words: ', total_words)\n",
    "print('Word: ID')\n",
    "print(\"--------------\")\n",
    "print(\"<oov>: \", tokenizer.word_index['<oov>'])\n",
    "print('Storng: ', tokenizer.word_index['strong'])\n",
    "print('And: ', tokenizer.word_index['and'])\n",
    "print('Consumption: ', tokenizer.word_index['consumption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 20px; border-radius: 10px;\">\n",
    "  <h3 style=\"color: #333333; text-align: center; font-weight: bold;\">Title Text Into Sequences</h3>\n",
    "  <p style=\"color: #666666; text-align: justify;\">let we have sentence like \"My Name Is Hakim\" and this will convert into sequeces with their respective tokens{\"I': 1, \"Name\": 2, \"Is\": 3, \"Hakim\": 4. So output will be [1,2,3,4]. Likewise all of our inputs will be like this</p>\n",
    "  <div style=\"background-color: #4CAF50; color: #ffffff; padding: 10px; border-radius: 5px; text-align: center;\">\n",
    "    <p style=\"margin: 0; text-align: center;\">Let's Make Sequences</p>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626e91be33994b9ab3c9efcf99e40059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "input_sequences = []\n",
    "for line in tqdm(data['text']):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    \n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 20px; border-radius: 10px;\">\n",
    "  <h3 style=\"color: #333333; text-align: center; font-weight: bold;\">Make all Titles in Same Length</h3>\n",
    "  <p style=\"color: #666666; text-align: justify; text-align: center;\">The length of every title has to be in same length.To make it we need to find the title which has maximum length.</p>\n",
    "  <div style=\"background-color: #4CAF50; color: #ffffff; padding: 10px; border-radius: 5px; text-align: center;\">\n",
    "    <p style=\"margin: 0; text-align: center;\">Making Pad Sequences</p>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_len = max(len(x) for x in input_sequences)\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #8b0000; padding: 10px; text-align: center;\">\n",
    "  <h1 style=\"color: #ffffff; text-shadow: 0 0 10px #ff6666;\">Prepare Features and Labels</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; padding: 20px; border-radius: 10px;\">\n",
    "  <p style=\"color: #666666; text-align: justify; text-align: center;\">Here, we consider last element of all sequences as a label. Then we need to perform encoding on labels corresponding to tatall_words</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create features and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34906, 21)\n",
      "(34906, 7091)\n"
     ]
    }
   ],
   "source": [
    "print(xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(xs,ys, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modeling\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 80, input_length= max_sequence_len - 1))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
    "model.add(LSTM(80, return_sequences=True))\n",
    "model.add(LSTM(80))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = load_model('final_model.h5')\n",
    "adam = Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 00:19:30.601190: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 792036336 exceeds 10% of free system memory.\n",
      "2024-10-09 00:19:34.483952: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 792036336 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - accuracy: 0.0350 - loss: 7.6804 - val_accuracy: 0.0401 - val_loss: 7.3446\n",
      "Epoch 2/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 34ms/step - accuracy: 0.0468 - loss: 6.9283 - val_accuracy: 0.0600 - val_loss: 7.3773\n",
      "Epoch 3/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 34ms/step - accuracy: 0.0614 - loss: 6.7240 - val_accuracy: 0.0666 - val_loss: 7.3946\n",
      "Epoch 4/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 30ms/step - accuracy: 0.0727 - loss: 6.5360 - val_accuracy: 0.0702 - val_loss: 7.4270\n",
      "Epoch 5/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 33ms/step - accuracy: 0.0783 - loss: 6.4391 - val_accuracy: 0.0715 - val_loss: 7.4252\n",
      "Epoch 6/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 33ms/step - accuracy: 0.0873 - loss: 6.3339 - val_accuracy: 0.0773 - val_loss: 7.4706\n",
      "Epoch 7/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 33ms/step - accuracy: 0.1002 - loss: 6.1464 - val_accuracy: 0.0854 - val_loss: 7.4876\n",
      "Epoch 8/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 34ms/step - accuracy: 0.1073 - loss: 6.0155 - val_accuracy: 0.0812 - val_loss: 7.5472\n",
      "Epoch 9/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 30ms/step - accuracy: 0.1105 - loss: 5.9115 - val_accuracy: 0.0812 - val_loss: 7.6355\n",
      "Epoch 10/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 31ms/step - accuracy: 0.1144 - loss: 5.8105 - val_accuracy: 0.0849 - val_loss: 7.6998\n",
      "Epoch 11/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - accuracy: 0.1202 - loss: 5.7112 - val_accuracy: 0.0846 - val_loss: 7.8155\n",
      "Epoch 12/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 22ms/step - accuracy: 0.1224 - loss: 5.6146 - val_accuracy: 0.0835 - val_loss: 7.9073\n",
      "Epoch 13/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.1307 - loss: 5.5256 - val_accuracy: 0.0868 - val_loss: 7.9866\n",
      "Epoch 14/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - accuracy: 0.1340 - loss: 5.4315 - val_accuracy: 0.0865 - val_loss: 8.0914\n",
      "Epoch 15/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 20ms/step - accuracy: 0.1384 - loss: 5.3213 - val_accuracy: 0.0882 - val_loss: 8.2278\n",
      "Epoch 16/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.1399 - loss: 5.2702 - val_accuracy: 0.0865 - val_loss: 8.3277\n",
      "Epoch 17/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 22ms/step - accuracy: 0.1464 - loss: 5.1797 - val_accuracy: 0.0877 - val_loss: 8.4079\n",
      "Epoch 18/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.1548 - loss: 5.0810 - val_accuracy: 0.0922 - val_loss: 8.5504\n",
      "Epoch 19/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 22ms/step - accuracy: 0.1590 - loss: 5.0322 - val_accuracy: 0.0932 - val_loss: 8.6298\n",
      "Epoch 20/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.1684 - loss: 4.9491 - val_accuracy: 0.0947 - val_loss: 8.7500\n",
      "Epoch 21/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.1754 - loss: 4.8515 - val_accuracy: 0.0987 - val_loss: 8.8527\n",
      "Epoch 22/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 22ms/step - accuracy: 0.1801 - loss: 4.7741 - val_accuracy: 0.0960 - val_loss: 8.9725\n",
      "Epoch 23/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - accuracy: 0.1875 - loss: 4.7047 - val_accuracy: 0.0954 - val_loss: 9.0665\n",
      "Epoch 24/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 20ms/step - accuracy: 0.1885 - loss: 4.6434 - val_accuracy: 0.0947 - val_loss: 9.1552\n",
      "Epoch 25/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.1924 - loss: 4.5910 - val_accuracy: 0.0954 - val_loss: 9.2465\n",
      "Epoch 26/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.1960 - loss: 4.5394 - val_accuracy: 0.0954 - val_loss: 9.3447\n",
      "Epoch 27/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.2035 - loss: 4.4840 - val_accuracy: 0.0957 - val_loss: 9.4552\n",
      "Epoch 28/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.2090 - loss: 4.4050 - val_accuracy: 0.0973 - val_loss: 9.5479\n",
      "Epoch 29/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.2142 - loss: 4.3275 - val_accuracy: 0.0932 - val_loss: 9.6225\n",
      "Epoch 30/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.2165 - loss: 4.3150 - val_accuracy: 0.0942 - val_loss: 9.7090\n",
      "Epoch 31/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 20ms/step - accuracy: 0.2222 - loss: 4.2614 - val_accuracy: 0.0975 - val_loss: 9.7794\n",
      "Epoch 32/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.2262 - loss: 4.2005 - val_accuracy: 0.0952 - val_loss: 9.8654\n",
      "Epoch 33/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 22ms/step - accuracy: 0.2312 - loss: 4.1651 - val_accuracy: 0.0964 - val_loss: 9.9763\n",
      "Epoch 34/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - accuracy: 0.2405 - loss: 4.1069 - val_accuracy: 0.0942 - val_loss: 10.0617\n",
      "Epoch 35/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 21ms/step - accuracy: 0.2464 - loss: 4.0568 - val_accuracy: 0.0948 - val_loss: 10.1175\n",
      "Epoch 36/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.2508 - loss: 4.0209 - val_accuracy: 0.0967 - val_loss: 10.1883\n",
      "Epoch 37/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.2595 - loss: 3.9516 - val_accuracy: 0.0962 - val_loss: 10.2802\n",
      "Epoch 38/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 22ms/step - accuracy: 0.2642 - loss: 3.9044 - val_accuracy: 0.0973 - val_loss: 10.3387\n",
      "Epoch 39/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.2699 - loss: 3.8546 - val_accuracy: 0.0952 - val_loss: 10.4273\n",
      "Epoch 40/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.2747 - loss: 3.8126 - val_accuracy: 0.0942 - val_loss: 10.4692\n",
      "Epoch 41/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 26ms/step - accuracy: 0.2750 - loss: 3.8055 - val_accuracy: 0.0952 - val_loss: 10.5405\n",
      "Epoch 42/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 20ms/step - accuracy: 0.2890 - loss: 3.7291 - val_accuracy: 0.0950 - val_loss: 10.6232\n",
      "Epoch 43/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 27ms/step - accuracy: 0.2889 - loss: 3.7091 - val_accuracy: 0.0964 - val_loss: 10.7104\n",
      "Epoch 44/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.2940 - loss: 3.6871 - val_accuracy: 0.0965 - val_loss: 10.7573\n",
      "Epoch 45/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 21ms/step - accuracy: 0.3056 - loss: 3.6026 - val_accuracy: 0.0958 - val_loss: 10.8199\n",
      "Epoch 46/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.3101 - loss: 3.5755 - val_accuracy: 0.0955 - val_loss: 10.9053\n",
      "Epoch 47/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 21ms/step - accuracy: 0.3149 - loss: 3.5439 - val_accuracy: 0.0962 - val_loss: 10.9393\n",
      "Epoch 48/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - accuracy: 0.3226 - loss: 3.4882 - val_accuracy: 0.0945 - val_loss: 11.0108\n",
      "Epoch 49/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 21ms/step - accuracy: 0.3257 - loss: 3.4676 - val_accuracy: 0.0974 - val_loss: 11.0632\n",
      "Epoch 50/50\n",
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 25ms/step - accuracy: 0.3321 - loss: 3.4236 - val_accuracy: 0.0967 - val_loss: 11.1422\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #8b0000; padding: 10px; text-align: center;\">\n",
    "  <h1 style=\"color: #ffffff; text-shadow: 0 0 10px #ff6666;\">Predicting Next Word Of Title</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am  good 39 s\n"
     ]
    }
   ],
   "source": [
    "seed_text = 'i am '\n",
    "next_words = 3\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
    "    predicted_probabilities = model.predict(token_list, verbose=0)  # Use predict() instead of predict_classes()\n",
    "    predicted_index = np.argmax(predicted_probabilities)  # Get the index of the word with highest probability\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "            \n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)\n",
    "\n",
    "    \n",
    "with open('max_sequence_length', 'wb') as file:\n",
    "    pickle.dump(max_sequence_len, file)\n",
    "    \n",
    "model.save('text_predictor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate recommendations based on user input\n",
    "def generate_recommendations(seed_text, next_words=6):\n",
    "    # Use trained model to predict next words\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
    "        predicted_probabilities = model.predict(token_list, verbose=0)\n",
    "        predicted_index = np.argmax(predicted_probabilities)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Capture user input\n",
    "user_input = input(\"Enter your query: \")\n",
    "\n",
    "# Generate and display recommendations\n",
    "recommendations = generate_recommendations(user_input)\n",
    "print(\"Recommendations:\", recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 612351,
     "sourceId": 1095715,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 748442,
     "sourceId": 1294572,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1621928,
     "sourceId": 2666044,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
