{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Read the text file\n",
    "with open('sherlock-holm.es_stories_plain-text_advs.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96314\n",
      "96314\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 17, 100)           820000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               150600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8200)              1238200   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,208,800\n",
      "Trainable params: 2,208,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model = load_model(\"mymodel.h5\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp,Y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2408/2408 [==============================] - 30s 10ms/step - loss: 6.3264 - accuracy: 0.0691 - val_loss: 5.9846 - val_accuracy: 0.0983\n",
      "Epoch 2/100\n",
      "2408/2408 [==============================] - 23s 10ms/step - loss: 5.6121 - accuracy: 0.1134 - val_loss: 5.7858 - val_accuracy: 0.1202\n",
      "Epoch 3/100\n",
      "2408/2408 [==============================] - 22s 9ms/step - loss: 5.2307 - accuracy: 0.1390 - val_loss: 5.7287 - val_accuracy: 0.1345\n",
      "Epoch 4/100\n",
      "2408/2408 [==============================] - 23s 10ms/step - loss: 4.9072 - accuracy: 0.1561 - val_loss: 5.7637 - val_accuracy: 0.1406\n",
      "Epoch 5/100\n",
      "2408/2408 [==============================] - 22s 9ms/step - loss: 4.6038 - accuracy: 0.1740 - val_loss: 5.8165 - val_accuracy: 0.1441\n",
      "Epoch 6/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 4.3118 - accuracy: 0.1951 - val_loss: 5.9305 - val_accuracy: 0.1377\n",
      "Epoch 7/100\n",
      "2408/2408 [==============================] - 18s 7ms/step - loss: 4.0326 - accuracy: 0.2156 - val_loss: 6.0521 - val_accuracy: 0.1397\n",
      "Epoch 8/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 3.7612 - accuracy: 0.2473 - val_loss: 6.1700 - val_accuracy: 0.1436\n",
      "Epoch 9/100\n",
      "2408/2408 [==============================] - 18s 7ms/step - loss: 3.5065 - accuracy: 0.2806 - val_loss: 6.3049 - val_accuracy: 0.1345\n",
      "Epoch 10/100\n",
      "2408/2408 [==============================] - 18s 7ms/step - loss: 3.2651 - accuracy: 0.3167 - val_loss: 6.4500 - val_accuracy: 0.1310\n",
      "Epoch 11/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 3.0417 - accuracy: 0.3530 - val_loss: 6.5895 - val_accuracy: 0.1283\n",
      "Epoch 12/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 2.8345 - accuracy: 0.3909 - val_loss: 6.7254 - val_accuracy: 0.1238\n",
      "Epoch 13/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 2.6416 - accuracy: 0.4282 - val_loss: 6.8779 - val_accuracy: 0.1231\n",
      "Epoch 14/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 2.4645 - accuracy: 0.4632 - val_loss: 6.9908 - val_accuracy: 0.1177\n",
      "Epoch 15/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 2.3015 - accuracy: 0.4963 - val_loss: 7.1273 - val_accuracy: 0.1194\n",
      "Epoch 16/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 2.1472 - accuracy: 0.5257 - val_loss: 7.2837 - val_accuracy: 0.1151\n",
      "Epoch 17/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 2.0077 - accuracy: 0.5553 - val_loss: 7.4430 - val_accuracy: 0.1123\n",
      "Epoch 18/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.8791 - accuracy: 0.5842 - val_loss: 7.5670 - val_accuracy: 0.1129\n",
      "Epoch 19/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.7609 - accuracy: 0.6088 - val_loss: 7.7104 - val_accuracy: 0.1119\n",
      "Epoch 20/100\n",
      "2408/2408 [==============================] - 18s 7ms/step - loss: 1.6527 - accuracy: 0.6336 - val_loss: 7.8617 - val_accuracy: 0.1083\n",
      "Epoch 21/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.5548 - accuracy: 0.6560 - val_loss: 8.0160 - val_accuracy: 0.1109\n",
      "Epoch 22/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.4631 - accuracy: 0.6740 - val_loss: 8.1744 - val_accuracy: 0.1078\n",
      "Epoch 23/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.3769 - accuracy: 0.6941 - val_loss: 8.3078 - val_accuracy: 0.1061\n",
      "Epoch 24/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.3022 - accuracy: 0.7101 - val_loss: 8.4402 - val_accuracy: 0.1040\n",
      "Epoch 25/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.2294 - accuracy: 0.7259 - val_loss: 8.5854 - val_accuracy: 0.1003\n",
      "Epoch 26/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.1656 - accuracy: 0.7393 - val_loss: 8.7190 - val_accuracy: 0.1004\n",
      "Epoch 27/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.1075 - accuracy: 0.7533 - val_loss: 8.8828 - val_accuracy: 0.0985\n",
      "Epoch 28/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.0507 - accuracy: 0.7660 - val_loss: 9.0133 - val_accuracy: 0.1006\n",
      "Epoch 29/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 1.0008 - accuracy: 0.7766 - val_loss: 9.1437 - val_accuracy: 0.0967\n",
      "Epoch 30/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.9565 - accuracy: 0.7860 - val_loss: 9.2761 - val_accuracy: 0.1007\n",
      "Epoch 31/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.9144 - accuracy: 0.7963 - val_loss: 9.3975 - val_accuracy: 0.0972\n",
      "Epoch 32/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.8731 - accuracy: 0.8062 - val_loss: 9.5181 - val_accuracy: 0.0953\n",
      "Epoch 33/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.8388 - accuracy: 0.8129 - val_loss: 9.6605 - val_accuracy: 0.0956\n",
      "Epoch 34/100\n",
      "2408/2408 [==============================] - 18s 8ms/step - loss: 0.8062 - accuracy: 0.8190 - val_loss: 9.7817 - val_accuracy: 0.0938\n",
      "Epoch 35/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.7768 - accuracy: 0.8254 - val_loss: 9.8958 - val_accuracy: 0.0957\n",
      "Epoch 36/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.7505 - accuracy: 0.8302 - val_loss: 10.0097 - val_accuracy: 0.0938\n",
      "Epoch 37/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.7239 - accuracy: 0.8356 - val_loss: 10.1280 - val_accuracy: 0.0950\n",
      "Epoch 38/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.7022 - accuracy: 0.8412 - val_loss: 10.2347 - val_accuracy: 0.0927\n",
      "Epoch 39/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.6785 - accuracy: 0.8446 - val_loss: 10.3491 - val_accuracy: 0.0934\n",
      "Epoch 40/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.6610 - accuracy: 0.8495 - val_loss: 10.4690 - val_accuracy: 0.0899\n",
      "Epoch 41/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.6401 - accuracy: 0.8534 - val_loss: 10.5643 - val_accuracy: 0.0888\n",
      "Epoch 42/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.6283 - accuracy: 0.8552 - val_loss: 10.6964 - val_accuracy: 0.0878\n",
      "Epoch 43/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.6115 - accuracy: 0.8582 - val_loss: 10.7568 - val_accuracy: 0.0912\n",
      "Epoch 44/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5972 - accuracy: 0.8619 - val_loss: 10.8286 - val_accuracy: 0.0888\n",
      "Epoch 45/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5858 - accuracy: 0.8636 - val_loss: 10.9579 - val_accuracy: 0.0922\n",
      "Epoch 46/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5736 - accuracy: 0.8664 - val_loss: 11.0235 - val_accuracy: 0.0902\n",
      "Epoch 47/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5610 - accuracy: 0.8683 - val_loss: 11.1215 - val_accuracy: 0.0903\n",
      "Epoch 48/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5535 - accuracy: 0.8689 - val_loss: 11.2144 - val_accuracy: 0.0890\n",
      "Epoch 49/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5435 - accuracy: 0.8713 - val_loss: 11.2834 - val_accuracy: 0.0916\n",
      "Epoch 50/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5355 - accuracy: 0.8731 - val_loss: 11.3544 - val_accuracy: 0.0865\n",
      "Epoch 51/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5289 - accuracy: 0.8739 - val_loss: 11.4498 - val_accuracy: 0.0888\n",
      "Epoch 52/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5204 - accuracy: 0.8754 - val_loss: 11.5146 - val_accuracy: 0.0891\n",
      "Epoch 53/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5133 - accuracy: 0.8760 - val_loss: 11.6164 - val_accuracy: 0.0874\n",
      "Epoch 54/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5066 - accuracy: 0.8781 - val_loss: 11.6458 - val_accuracy: 0.0874\n",
      "Epoch 55/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.5039 - accuracy: 0.8768 - val_loss: 11.7241 - val_accuracy: 0.0904\n",
      "Epoch 56/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4964 - accuracy: 0.8796 - val_loss: 11.8155 - val_accuracy: 0.0868\n",
      "Epoch 57/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4916 - accuracy: 0.8787 - val_loss: 11.8806 - val_accuracy: 0.0893\n",
      "Epoch 58/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4862 - accuracy: 0.8813 - val_loss: 11.9425 - val_accuracy: 0.0888\n",
      "Epoch 59/100\n",
      "2408/2408 [==============================] - 18s 8ms/step - loss: 0.4871 - accuracy: 0.8799 - val_loss: 11.9862 - val_accuracy: 0.0849\n",
      "Epoch 60/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4830 - accuracy: 0.8799 - val_loss: 12.0413 - val_accuracy: 0.0902\n",
      "Epoch 61/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4760 - accuracy: 0.8819 - val_loss: 12.1199 - val_accuracy: 0.0872\n",
      "Epoch 62/100\n",
      "2408/2408 [==============================] - 18s 7ms/step - loss: 0.4725 - accuracy: 0.8823 - val_loss: 12.1566 - val_accuracy: 0.0875\n",
      "Epoch 63/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4672 - accuracy: 0.8834 - val_loss: 12.2675 - val_accuracy: 0.0866\n",
      "Epoch 64/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4703 - accuracy: 0.8815 - val_loss: 12.2789 - val_accuracy: 0.0872\n",
      "Epoch 65/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4604 - accuracy: 0.8850 - val_loss: 12.3658 - val_accuracy: 0.0884\n",
      "Epoch 66/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4607 - accuracy: 0.8844 - val_loss: 12.4011 - val_accuracy: 0.0902\n",
      "Epoch 67/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4615 - accuracy: 0.8834 - val_loss: 12.4657 - val_accuracy: 0.0891\n",
      "Epoch 68/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4528 - accuracy: 0.8854 - val_loss: 12.5331 - val_accuracy: 0.0866\n",
      "Epoch 69/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4477 - accuracy: 0.8870 - val_loss: 12.5604 - val_accuracy: 0.0848\n",
      "Epoch 70/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4538 - accuracy: 0.8840 - val_loss: 12.6065 - val_accuracy: 0.0820\n",
      "Epoch 71/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4464 - accuracy: 0.8863 - val_loss: 12.6952 - val_accuracy: 0.0846\n",
      "Epoch 72/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4488 - accuracy: 0.8844 - val_loss: 12.7447 - val_accuracy: 0.0842\n",
      "Epoch 73/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4452 - accuracy: 0.8854 - val_loss: 12.7489 - val_accuracy: 0.0878\n",
      "Epoch 74/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4452 - accuracy: 0.8856 - val_loss: 12.7997 - val_accuracy: 0.0829\n",
      "Epoch 75/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4371 - accuracy: 0.8880 - val_loss: 12.8692 - val_accuracy: 0.0860\n",
      "Epoch 76/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4437 - accuracy: 0.8852 - val_loss: 12.9079 - val_accuracy: 0.0890\n",
      "Epoch 77/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4377 - accuracy: 0.8863 - val_loss: 12.9222 - val_accuracy: 0.0836\n",
      "Epoch 78/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4452 - accuracy: 0.8844 - val_loss: 12.9896 - val_accuracy: 0.0870\n",
      "Epoch 79/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4308 - accuracy: 0.8879 - val_loss: 13.0233 - val_accuracy: 0.0839\n",
      "Epoch 80/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4334 - accuracy: 0.8866 - val_loss: 13.1083 - val_accuracy: 0.0865\n",
      "Epoch 81/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4333 - accuracy: 0.8867 - val_loss: 13.0978 - val_accuracy: 0.0869\n",
      "Epoch 82/100\n",
      "2408/2408 [==============================] - 18s 8ms/step - loss: 0.4290 - accuracy: 0.8874 - val_loss: 13.1198 - val_accuracy: 0.0851\n",
      "Epoch 83/100\n",
      "2408/2408 [==============================] - 18s 7ms/step - loss: 0.4322 - accuracy: 0.8864 - val_loss: 13.1839 - val_accuracy: 0.0861\n",
      "Epoch 84/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4314 - accuracy: 0.8862 - val_loss: 13.2425 - val_accuracy: 0.0836\n",
      "Epoch 85/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4284 - accuracy: 0.8871 - val_loss: 13.3007 - val_accuracy: 0.0844\n",
      "Epoch 86/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4295 - accuracy: 0.8866 - val_loss: 13.3486 - val_accuracy: 0.0858\n",
      "Epoch 87/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4333 - accuracy: 0.8851 - val_loss: 13.3646 - val_accuracy: 0.0870\n",
      "Epoch 88/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4203 - accuracy: 0.8890 - val_loss: 13.3843 - val_accuracy: 0.0871\n",
      "Epoch 89/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4278 - accuracy: 0.8862 - val_loss: 13.4531 - val_accuracy: 0.0815\n",
      "Epoch 90/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4303 - accuracy: 0.8851 - val_loss: 13.4558 - val_accuracy: 0.0831\n",
      "Epoch 91/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4242 - accuracy: 0.8866 - val_loss: 13.4798 - val_accuracy: 0.0843\n",
      "Epoch 92/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4254 - accuracy: 0.8869 - val_loss: 13.5260 - val_accuracy: 0.0849\n",
      "Epoch 93/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4209 - accuracy: 0.8879 - val_loss: 13.5871 - val_accuracy: 0.0851\n",
      "Epoch 94/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4248 - accuracy: 0.8865 - val_loss: 13.6672 - val_accuracy: 0.0818\n",
      "Epoch 95/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4243 - accuracy: 0.8859 - val_loss: 13.6637 - val_accuracy: 0.0856\n",
      "Epoch 96/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4248 - accuracy: 0.8859 - val_loss: 13.6539 - val_accuracy: 0.0848\n",
      "Epoch 97/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4209 - accuracy: 0.8869 - val_loss: 13.7002 - val_accuracy: 0.0838\n",
      "Epoch 98/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4203 - accuracy: 0.8869 - val_loss: 13.7418 - val_accuracy: 0.0850\n",
      "Epoch 99/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4178 - accuracy: 0.8885 - val_loss: 13.7658 - val_accuracy: 0.0851\n",
      "Epoch 100/100\n",
      "2408/2408 [==============================] - 17s 7ms/step - loss: 0.4245 - accuracy: 0.8853 - val_loss: 13.8307 - val_accuracy: 0.0843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bab9f60a30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=100, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "This ensures that the model works with the soul it is\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"This ensures that the model works with the\"\n",
    "next_words = 3\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"bestModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"myModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
